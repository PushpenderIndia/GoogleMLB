{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10652824,"sourceType":"datasetVersion","datasetId":6581138}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview of MLB Homeruns Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nmlb_homeruns_df = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2016-mlb-homeruns.csv')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-04T04:19:00.209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb_homeruns_df.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-04T04:19:00.209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing & Training in Batches","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport os\nimport requests\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM, TimeDistributed\nfrom tensorflow.keras.optimizers import Adam\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tqdm import tqdm\nimport tensorflow.keras.backend as K\nimport gc\n\n# Load pre-trained CNN model (feature extractor)\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze pre-trained layers\nfeature_extractor = Model(inputs=base_model.input, outputs=Flatten()(base_model.output))  # Extracted features\n\n# Define the LSTM-based regression model\nmodel = Sequential([\n    TimeDistributed(feature_extractor, input_shape=(50, 224, 224, 3)),  # Apply CNN to each frame\n    LSTM(256, return_sequences=False),  # LSTM processes extracted features\n    Dense(512, activation='relu'),\n    Dropout(0.3),\n    Dense(3)  # Predict ExitVelocity, HitDistance, LaunchAngle\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n\n# Function to download video\ndef download_video(video_url, save_path):\n    response = requests.get(video_url, stream=True)\n    with open(save_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            file.write(chunk)\n    return save_path\n\n# Function to extract frames from video\ndef preprocess_video(video_url, save_path, frame_count=50):\n    video_path = download_video(video_url, f'{save_path}.mp4')\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_ids = np.linspace(0, total_frames - 1, frame_count, dtype=int)  # Sample evenly\n    \n    for fid in frame_ids:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n        ret, frame = cap.read()\n        if not ret:\n            continue\n        frame = cv2.resize(frame, (224, 224)) / 255.0  # Normalize\n        frames.append(frame)\n    \n    cap.release()\n    os.remove(video_path)  # Remove temp file\n    return np.array(frames) if len(frames) == frame_count else None  # Ensure 10 frames\n\n# Load and merge datasets\ndf1 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2016-mlb-homeruns.csv')\ndf2 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2017-mlb-homeruns.csv')\ndf3 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2024-mlb-homeruns.csv')\ndf = pd.concat([df1, df2, df3], ignore_index=True)\n\n# Prepare training data\nbatch_size = 50\nnum_batches = len(df) // batch_size + (len(df) % batch_size != 0)\n\n# Create temp directory for videos\nos.makedirs(\"temp_videos\", exist_ok=True)\n\nfor batch_idx in range(num_batches):\n    print(f\"Processing batch {batch_idx + 1}/{num_batches}\")\n    df_batch = df[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n    X, y = [], []\n    \n    # Process videos with proper tqdm progress tracking\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        futures = {executor.submit(preprocess_video, row['video'], 'temp_videos/' + row['play_id']): row for _, row in df_batch.iterrows()}\n        \n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing Videos\"):\n            res = future.result()\n            if res is not None:\n                X.append(res)\n                y.append([futures[future]['ExitVelocity'], futures[future]['HitDistance'], futures[future]['LaunchAngle']])\n    \n    if len(X) == 0:\n        print(\"Skipping batch due to no valid videos.\")\n        continue\n\n    X = np.array(X)  # Shape: (batch_size, 10, 224, 224, 3)\n    y = np.array(y)  # Shape: (batch_size, 3)\n\n    print(\"Split data into train and test\")\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    print(\"Train model\")\n    model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n\n    print(\"Deleting Previous Saved model\")\n    if os.path.exists(f'model_batch_{batch_idx}.h5'):\n        os.remove(f'model_batch_{batch_idx}.h5')\n    \n    print(\"Save model after each batch\")\n    model.save(f'model_batch_{batch_idx + 1}.h5')\n    print(f\"Model saved after batch {batch_idx + 1}\")\n\n    print(\"Evaluate model\")\n    loss, mae = model.evaluate(X_test, y_test)\n    print(f'Batch {batch_idx + 1} - Test Loss: {loss}, Test MAE: {mae}')\n\n    # Clear the TensorFlow session to release memory\n    K.clear_session()\n    \n    # Trigger garbage collection to free up unused memory\n    gc.collect()\n\n    # Clear variables (X and y data) that are no longer needed\n    X = []\n    y = []\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-04T04:19:00.209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Making Prediction by Loading Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport cv2\nimport os\nimport requests\n\n# Load the trained model\nmodel_path = \"/kaggle/working/model_batch_8.h5\"  # Replace 'X' with the latest batch number\nmodel = tf.keras.models.load_model(model_path, compile=False)\n\n# Recompile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='mse',  # Explicitly set the loss function again\n              metrics=['mae'])\n\n# Function to preprocess new video\ndef preprocess_video(video_url, save_path, frame_count=50):\n    response = requests.get(video_url, stream=True)\n    with open(save_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            file.write(chunk)\n\n    cap = cv2.VideoCapture(save_path)\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_ids = np.linspace(0, total_frames - 1, frame_count, dtype=int)\n\n    for fid in frame_ids:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n        ret, frame = cap.read()\n        if not ret:\n            continue\n        frame = cv2.resize(frame, (224, 224)) / 255.0  # Normalize\n        frames.append(frame)\n\n    cap.release()\n    os.remove(save_path)  # Remove temporary video file\n\n    if len(frames) == frame_count:\n        return np.array(frames)\n    else:\n        return None  # Return None if video does not have enough frames\n\n# Path to the new video for prediction\nrow_index = 700\nvideo_url = mlb_homeruns_df['video'][row_index]  # Replace with actual video URL\nvideo_save_path = \"temp_video.mp4\"\n\n# Preprocess video\nvideo_frames = preprocess_video(video_url, video_save_path)\n\nif video_frames is not None:\n    video_frames = np.expand_dims(video_frames, axis=0)  # Add batch dimension (1, 50, 224, 224, 3)\n\n    # Make prediction\n    predictions = model.predict(video_frames)\n\n    # Display predicted values\n    print(f\"Predicted ExitVelocity: {predictions[0][0]:.2f}\")\n    print(f\"Predicted HitDistance: {predictions[0][1]:.2f}\")\n    print(f\"Predicted LaunchAngle: {predictions[0][2]:.2f}\")\n\n    print(f\"\\n\\nActual ExitVelocity: {mlb_homeruns_df['ExitVelocity'][row_index]}\")\n    print(f\"Actual HitDistance: {mlb_homeruns_df['HitDistance'][row_index]}\")\n    print(f\"Actual LaunchAngle: {mlb_homeruns_df['LaunchAngle'][row_index]}\")\nelse:\n    print(\"Error: Not enough valid frames in the video.\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-04T04:19:00.209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlb_homeruns_df.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-04T04:19:00.209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport os\nimport requests\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM, TimeDistributed\nfrom tensorflow.keras.optimizers import Adam\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tqdm import tqdm\nimport tensorflow.keras.backend as K\nimport gc\n\n# Load pre-trained CNN model (feature extractor)\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze pre-trained layers\nfeature_extractor = Model(inputs=base_model.input, outputs=Flatten()(base_model.output))  # Extracted features\n\n# Define the LSTM-based regression model\nmodel = Sequential([\n    TimeDistributed(feature_extractor, input_shape=(60, 224, 224, 3)),  # Apply CNN to each frame\n    LSTM(256, return_sequences=False),  # LSTM processes extracted features\n    Dense(512, activation='relu'),\n    Dropout(0.3),\n    Dense(3)  # Predict ExitVelocity, HitDistance, LaunchAngle\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\nmodel.summary()\n\n# Function to download video\ndef download_video(video_url, save_path):\n    response = requests.get(video_url, stream=True)\n    with open(save_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            file.write(chunk)\n    return save_path\n\n# Function to extract frames from video\ndef preprocess_video(video_url, save_path, frame_count=60):\n    video_path = download_video(video_url, f'{save_path}.mp4')\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_ids = np.linspace(0, total_frames - 1, frame_count, dtype=int)  # Sample evenly\n    \n    for fid in frame_ids:\n        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n        ret, frame = cap.read()\n        if not ret:\n            continue\n        frame = cv2.resize(frame, (224, 224)) / 255.0  # Normalize\n        frames.append(frame)\n    \n    cap.release()\n    os.remove(video_path)  # Remove temp file\n    return np.array(frames) if len(frames) == frame_count else None \n\n# Load and merge datasets\ndf1 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2016-mlb-homeruns.csv')\ndf2 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2017-mlb-homeruns.csv')\ndf3 = pd.read_csv('/kaggle/input/mlb-fan-content-interaction/2024-mlb-homeruns.csv')\ndf = pd.concat([df1, df2, df3], ignore_index=True)\n\n# Prepare training data\nbatch_size = 30\nnum_batches = len(df) // batch_size + (len(df) % batch_size != 0)\n\n# Create temp directory for videos\nos.makedirs(\"temp_videos\", exist_ok=True)\n\nfor batch_idx in range(num_batches):\n    print(f\"Processing batch {batch_idx + 1}/{num_batches}\")\n    df_batch = df[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n    X, y = [], []\n    \n    # Process videos with proper tqdm progress tracking\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        futures = {executor.submit(preprocess_video, row['video'], 'temp_videos/' + row['play_id']): row for _, row in df_batch.iterrows()}\n        \n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing Videos\"):\n            res = future.result()\n            if res is not None:\n                X.append(res)\n                y.append([futures[future]['ExitVelocity'], futures[future]['HitDistance'], futures[future]['LaunchAngle']])\n    \n    if len(X) == 0:\n        print(\"Skipping batch due to no valid videos.\")\n        continue\n\n    X = np.array(X)  # Shape: (batch_size, 10, 224, 224, 3)\n    y = np.array(y)  # Shape: (batch_size, 3)\n\n    print(\"Split data into train and test\")\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    print(\"Train model\")\n    model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n\n    print(\"Deleting Previous Saved model\")\n    if os.path.exists(f'model_batch_{batch_idx}.h5'):\n        os.remove(f'model_batch_{batch_idx}.h5')\n    \n    print(\"Save model after each batch\")\n    model.save(f'model_batch_{batch_idx + 1}.h5')\n    print(f\"Model saved after batch {batch_idx + 1}\")\n\n    print(\"Evaluate model\")\n    loss, mae = model.evaluate(X_test, y_test)\n    print(f'Batch {batch_idx + 1} - Test Loss: {loss}, Test MAE: {mae}')\n\n    # Clear the TensorFlow session to release memory\n    K.clear_session()\n    \n    # Trigger garbage collection to free up unused memory\n    gc.collect()\n\n    # Clear variables (X and y data) that are no longer needed\n    X = []\n    y = []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T11:24:17.958283Z","iopub.execute_input":"2025-02-04T11:24:17.958469Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100352\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │     \u001b[38;5;34m103,023,616\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │     <span style=\"color: #00af00; text-decoration-color: #00af00\">103,023,616</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,744,451\u001b[0m (483.49 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,744,451</span> (483.49 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,156,739\u001b[0m (393.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,156,739</span> (393.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Processing batch 1/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:17<00:00,  6.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 63s/step - loss: 52451.8398 - mae: 166.3096 - val_loss: 59352.7500 - val_mae: 180.4822\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 54457.9258 - mae: 171.3789 - val_loss: 58130.1250 - val_mae: 178.5312\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 51025.0391 - mae: 163.6112 - val_loss: 56861.6680 - val_mae: 176.2828\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 51675.0195 - mae: 166.5085 - val_loss: 55478.6562 - val_mae: 173.6411\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 47888.2578 - mae: 158.1932 - val_loss: 53967.7070 - val_mae: 170.5566\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 46324.1055 - mae: 155.0725 - val_loss: 52308.1406 - val_mae: 166.9798\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 47388.0430 - mae: 157.7618 - val_loss: 50498.2969 - val_mae: 162.8856\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 45907.1758 - mae: 153.5554 - val_loss: 48554.0742 - val_mae: 158.2828\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 42042.1562 - mae: 144.3829 - val_loss: 46493.3750 - val_mae: 153.1806\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 41239.4766 - mae: 142.4671 - val_loss: 44312.3633 - val_mae: 147.5723\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 1\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 44312.3633 - mae: 147.5723\nBatch 1 - Test Loss: 44312.36328125, Test MAE: 147.57232666015625\nProcessing batch 2/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:14<00:00,  6.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 34s/step - loss: 41164.8984 - mae: 140.6461 - val_loss: 36728.6133 - val_mae: 131.1816\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 39101.9922 - mae: 135.3039 - val_loss: 34505.0352 - val_mae: 125.5018\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 36783.9492 - mae: 130.5264 - val_loss: 32221.6777 - val_mae: 120.3028\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 35229.6484 - mae: 126.9586 - val_loss: 29892.3340 - val_mae: 115.0872\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 31648.1836 - mae: 119.3543 - val_loss: 27550.7441 - val_mae: 109.3755\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 30732.1367 - mae: 116.7677 - val_loss: 25209.3457 - val_mae: 103.0872\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 27461.5527 - mae: 108.2214 - val_loss: 22905.3457 - val_mae: 96.1536\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 25300.4414 - mae: 102.3806 - val_loss: 20659.4824 - val_mae: 88.6736\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 23189.2207 - mae: 94.8440 - val_loss: 18498.9316 - val_mae: 81.0859\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 20312.5156 - mae: 87.8230 - val_loss: 16447.6328 - val_mae: 76.0339\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 2\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 16447.6328 - mae: 76.0339\nBatch 2 - Test Loss: 16447.6328125, Test MAE: 76.03392791748047\nProcessing batch 3/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:12<00:00,  6.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 17096.4082 - mae: 79.2406 - val_loss: 16700.8086 - val_mae: 78.0201\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 14957.5078 - mae: 74.6277 - val_loss: 14737.9795 - val_mae: 75.4053\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 13364.6660 - mae: 72.0606 - val_loss: 12908.8438 - val_mae: 72.4228\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 11343.7812 - mae: 68.9159 - val_loss: 11203.5244 - val_mae: 68.9051\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 9707.5078 - mae: 64.4633 - val_loss: 9624.5977 - val_mae: 64.8948\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 7950.8564 - mae: 59.6146 - val_loss: 8169.9819 - val_mae: 60.4316\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 6700.3838 - mae: 55.4908 - val_loss: 6841.4937 - val_mae: 55.6867\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 5651.9365 - mae: 51.8763 - val_loss: 5648.0483 - val_mae: 50.6758\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 4656.3486 - mae: 47.0793 - val_loss: 4595.7500 - val_mae: 45.5187\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 3871.4741 - mae: 42.1307 - val_loss: 3675.6379 - val_mae: 40.3385\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 3\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 3675.6379 - mae: 40.3385\nBatch 3 - Test Loss: 3675.637939453125, Test MAE: 40.33849334716797\nProcessing batch 4/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:14<00:00,  6.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 6927.2871 - mae: 44.2776 - val_loss: 1589.0812 - val_mae: 27.6005\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 6215.8179 - mae: 42.6984 - val_loss: 1222.8564 - val_mae: 23.5789\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 7817.6797 - mae: 44.8819 - val_loss: 989.0982 - val_mae: 20.3766\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 9442.1562 - mae: 45.8972 - val_loss: 856.3937 - val_mae: 18.2275\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 7499.4346 - mae: 39.0068 - val_loss: 762.3893 - val_mae: 16.9668\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 5736.2314 - mae: 35.3349 - val_loss: 700.5187 - val_mae: 16.4880\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 7124.6768 - mae: 37.2764 - val_loss: 670.7081 - val_mae: 16.2124\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 8083.4971 - mae: 38.7249 - val_loss: 674.7952 - val_mae: 16.3633\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 8945.5127 - mae: 42.4574 - val_loss: 690.2457 - val_mae: 16.4201\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 6424.3081 - mae: 35.7234 - val_loss: 711.9956 - val_mae: 16.6341\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 4\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 711.9956 - mae: 16.6341\nBatch 4 - Test Loss: 711.99560546875, Test MAE: 16.634103775024414\nProcessing batch 5/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:14<00:00,  6.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 2024.9835 - mae: 25.2253 - val_loss: 1281.1638 - val_mae: 23.1525\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 2743.7136 - mae: 27.1225 - val_loss: 1236.6149 - val_mae: 22.5491\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 3752.2288 - mae: 28.2716 - val_loss: 1164.8716 - val_mae: 21.6667\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 3264.7800 - mae: 26.2430 - val_loss: 1068.8876 - val_mae: 20.4604\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1895.6185 - mae: 24.0200 - val_loss: 953.7471 - val_mae: 19.1290\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1619.1229 - mae: 21.1869 - val_loss: 848.2963 - val_mae: 17.7504\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1656.9677 - mae: 19.0301 - val_loss: 757.4786 - val_mae: 16.6039\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 2397.8074 - mae: 20.8745 - val_loss: 682.9893 - val_mae: 15.5837\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1681.7805 - mae: 19.4917 - val_loss: 611.3349 - val_mae: 14.6928\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1954.1545 - mae: 19.0313 - val_loss: 564.1060 - val_mae: 14.5363\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 5\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 564.1060 - mae: 14.5363\nBatch 5 - Test Loss: 564.10595703125, Test MAE: 14.536346435546875\nProcessing batch 6/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:16<00:00,  6.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 1585.7112 - mae: 18.5220 - val_loss: 610.7850 - val_mae: 15.4737\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 2441.7908 - mae: 21.3927 - val_loss: 561.0556 - val_mae: 14.8655\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 2143.4387 - mae: 17.4983 - val_loss: 523.0910 - val_mae: 14.6637\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 2347.9326 - mae: 19.7337 - val_loss: 492.8875 - val_mae: 14.3379\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 2240.8975 - mae: 20.0657 - val_loss: 462.7755 - val_mae: 13.9064\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1260.9563 - mae: 16.1612 - val_loss: 435.3621 - val_mae: 13.6563\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 3310.3784 - mae: 20.3988 - val_loss: 424.6188 - val_mae: 13.5666\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1983.8754 - mae: 17.3822 - val_loss: 412.9150 - val_mae: 13.3561\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1156.8306 - mae: 13.0520 - val_loss: 401.9831 - val_mae: 13.1503\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1279.6782 - mae: 14.2156 - val_loss: 396.9344 - val_mae: 13.0674\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 6\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 396.9344 - mae: 13.0674\nBatch 6 - Test Loss: 396.9344482421875, Test MAE: 13.067401885986328\nProcessing batch 7/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:14<00:00,  6.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 2433.6448 - mae: 19.6252 - val_loss: 152.7748 - val_mae: 8.0084\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 1650.9789 - mae: 19.6179 - val_loss: 144.7441 - val_mae: 7.6433\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 1655.1335 - mae: 18.6881 - val_loss: 138.1997 - val_mae: 7.3829\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 1384.3755 - mae: 17.5053 - val_loss: 130.2441 - val_mae: 7.0651\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 4103.0781 - mae: 22.4063 - val_loss: 127.6108 - val_mae: 6.9662\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1206.5479 - mae: 15.0615 - val_loss: 125.0233 - val_mae: 6.8771\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 2173.7454 - mae: 17.9740 - val_loss: 122.8440 - val_mae: 6.8165\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 2281.6309 - mae: 18.7091 - val_loss: 120.0958 - val_mae: 6.7511\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 3690.4492 - mae: 23.0499 - val_loss: 117.4879 - val_mae: 6.6776\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 1946.1150 - mae: 16.9863 - val_loss: 114.7867 - val_mae: 6.6554\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 7\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 114.7867 - mae: 6.6554\nBatch 7 - Test Loss: 114.7867431640625, Test MAE: 6.655441761016846\nProcessing batch 8/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:13<00:00,  6.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 532.4362 - mae: 15.1674 - val_loss: 283.0580 - val_mae: 10.1286\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 245.9408 - mae: 10.3863 - val_loss: 262.7354 - val_mae: 9.6989\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 476.2622 - mae: 13.9542 - val_loss: 246.4180 - val_mae: 9.2282\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 349.4420 - mae: 12.4493 - val_loss: 233.7134 - val_mae: 8.9324\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 440.4043 - mae: 13.5873 - val_loss: 221.1510 - val_mae: 8.5184\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 303.0835 - mae: 12.6361 - val_loss: 210.9222 - val_mae: 8.1819\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 301.4189 - mae: 12.7062 - val_loss: 202.0732 - val_mae: 8.0227\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 314.3021 - mae: 11.6276 - val_loss: 195.0072 - val_mae: 8.1486\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 279.5703 - mae: 11.5136 - val_loss: 191.2823 - val_mae: 8.5609\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 246.6121 - mae: 10.9297 - val_loss: 187.8320 - val_mae: 8.5070\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 8\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 187.8320 - mae: 8.5070\nBatch 8 - Test Loss: 187.83204650878906, Test MAE: 8.507046699523926\nProcessing batch 9/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:15<00:00,  6.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 34s/step - loss: 351.3359 - mae: 11.9115 - val_loss: 179.0618 - val_mae: 9.5803\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 591.0876 - mae: 15.5788 - val_loss: 189.4570 - val_mae: 9.6956\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 564.7527 - mae: 14.4955 - val_loss: 207.1574 - val_mae: 9.8882\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 257.3746 - mae: 11.2591 - val_loss: 226.1882 - val_mae: 10.2085\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 222.2848 - mae: 10.4608 - val_loss: 245.5776 - val_mae: 10.5378\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 296.7558 - mae: 11.7498 - val_loss: 264.7137 - val_mae: 10.9900\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 268.8818 - mae: 11.3467 - val_loss: 282.9422 - val_mae: 11.3952\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 335.9872 - mae: 12.3155 - val_loss: 301.4220 - val_mae: 11.8065\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 404.7775 - mae: 13.6087 - val_loss: 310.6906 - val_mae: 11.9322\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 349.3473 - mae: 12.4125 - val_loss: 320.9477 - val_mae: 12.1455\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 9\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 320.9477 - mae: 12.1455\nBatch 9 - Test Loss: 320.9477233886719, Test MAE: 12.145477294921875\nProcessing batch 10/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:15<00:00,  6.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 34s/step - loss: 574.7592 - mae: 14.6953 - val_loss: 185.3759 - val_mae: 9.4408\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 581.2664 - mae: 14.6124 - val_loss: 185.9819 - val_mae: 9.4040\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 485.8528 - mae: 13.4840 - val_loss: 187.5406 - val_mae: 9.4066\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 470.8186 - mae: 13.3196 - val_loss: 188.6086 - val_mae: 9.5420\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 562.8091 - mae: 15.4169 - val_loss: 187.6433 - val_mae: 9.4506\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 519.8569 - mae: 15.3843 - val_loss: 185.6766 - val_mae: 9.4699\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 527.9682 - mae: 15.0887 - val_loss: 184.7634 - val_mae: 9.6079\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 392.7201 - mae: 12.3091 - val_loss: 184.4211 - val_mae: 9.6665\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 626.7759 - mae: 16.2254 - val_loss: 184.8713 - val_mae: 9.7093\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 379.7233 - mae: 12.6645 - val_loss: 185.7734 - val_mae: 9.7977\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 10\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 185.7734 - mae: 9.7977\nBatch 10 - Test Loss: 185.77342224121094, Test MAE: 9.797739028930664\nProcessing batch 11/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos: 100%|██████████| 30/30 [03:17<00:00,  6.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"Split data into train and test\nTrain model\nEpoch 1/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 34s/step - loss: 387.3683 - mae: 12.5657 - val_loss: 121.2895 - val_mae: 7.3121\nEpoch 2/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 494.1400 - mae: 14.3322 - val_loss: 125.3732 - val_mae: 7.3387\nEpoch 3/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 385.5602 - mae: 13.9369 - val_loss: 133.8627 - val_mae: 7.6079\nEpoch 4/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 323.8651 - mae: 12.1799 - val_loss: 139.1204 - val_mae: 7.7830\nEpoch 5/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 323.9953 - mae: 11.1509 - val_loss: 142.7835 - val_mae: 7.8872\nEpoch 6/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 380.9462 - mae: 12.6862 - val_loss: 145.2580 - val_mae: 7.9860\nEpoch 7/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 378.1563 - mae: 13.4197 - val_loss: 141.3626 - val_mae: 7.8041\nEpoch 8/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 483.5509 - mae: 14.8976 - val_loss: 137.1983 - val_mae: 7.6491\nEpoch 9/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 253.0176 - mae: 9.9122 - val_loss: 135.0648 - val_mae: 7.6810\nEpoch 10/10\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - loss: 210.7616 - mae: 9.7405 - val_loss: 134.9762 - val_mae: 7.6370\nDeleting Previous Saved model\nSave model after each batch\nModel saved after batch 11\nEvaluate model\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 134.9762 - mae: 7.6370\nBatch 11 - Test Loss: 134.97621154785156, Test MAE: 7.636997699737549\nProcessing batch 12/549\n","output_type":"stream"},{"name":"stderr","text":"Processing Videos:  67%|██████▋   | 20/30 [02:13<00:14,  1.41s/it]","output_type":"stream"}],"execution_count":null}]}